{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMwsrCp9iAurpgI0RcAbeRJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Task 7: Introduction to Natural Language (Text) Processing"],"metadata":{"id":"L982FdumDCVn"}},{"cell_type":"markdown","source":["## Section 1: Setup and Sample Dataset"],"metadata":{"id":"gk9AwRFXDO6n"}},{"cell_type":"markdown","source":["### **Task 1**: Import Libraries and Sample Data\n","*Instruction*: Import the necessary libraries and define a sample dataset for sentiment classification."],"metadata":{"id":"tG2LLFb4DSrf"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import nltk\n","import string\n","\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","# Sample data\n","data = {\n","    'text': [\n","        'I love this movie. It was fantastic!',\n","        'Terrible acting and horrible plot.',\n","        'An excellent film with great characters.',\n","        'Worst movie I have ever seen.',\n","        'Absolutely wonderful! A must-watch.',\n","        'It was okay, nothing special.',\n","        'Bad movie, waste of time.',\n","        'Pretty good, I liked it.',\n","        'Not great, but not terrible.',\n","        'Awful! Never again.'\n","    ],\n","    'label': [1, 0, 1, 0, 1, 1, 0, 1, 0, 0]  # 1 = positive, 0 = negative\n","}\n","\n","df = pd.DataFrame(data)\n","df.head()"],"metadata":{"id":"G6YtbgenDSWH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Section 2: Text Preprocessing"],"metadata":{"id":"03CKwCBtDzRL"}},{"cell_type":"markdown","source":["### **Task 2**: Clean the Text\n","\n","*Instruction*: Lowercase the text, remove punctuation, stopwords, and tokenize the sentences.\n"],"metadata":{"id":"oh1W_9m5DuzF"}},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","stop_words = set(stopwords.words('english'))\n","\n","def preprocess(text):\n","    text = text.lower()\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    tokens = word_tokenize(text)\n","    filtered = [word for word in tokens if word not in stop_words]\n","    return ' '.join(filtered)\n","\n","df['cleaned'] = df['text'].apply(preprocess)\n","df[['text', 'cleaned']].head()"],"metadata":{"id":"SQTsWR6GDn6e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Section 3: Text Vectorization"],"metadata":{"id":"mVV1BgZvEE3a"}},{"cell_type":"markdown","source":["### **Task 3**: Convert Text to Numerical Features\n","\n","*Instruction*: Use both Bag of Words and TF-IDF vectorization to convert the cleaned text.\n"],"metadata":{"id":"opUK7Z7LEIr4"}},{"cell_type":"code","source":["# Bag of Words\n","cv = CountVectorizer()\n","X_bow = cv.fit_transform(df['cleaned'])\n","\n","# TF-IDF\n","tfidf = TfidfVectorizer()\n","X_tfidf = tfidf.fit_transform(df['cleaned'])"],"metadata":{"id":"UW3FMdjQEEl3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Section 4: Train a Classifier"],"metadata":{"id":"GNO0DPi3EpgF"}},{"cell_type":"markdown","source":["### **Task 4**: Sentiment Classification with Naive Bayes\n","\n","*Instruction*: Split the dataset, train a classifier using both feature sets, and evaluate the performance."],"metadata":{"id":"W74DNGaJEtdj"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['label'], test_size=0.3, random_state=42)\n","\n","model = MultinomialNB()\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_test)\n","\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"],"metadata":{"id":"aM8iWEAXEOmE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Section 5: Mini Challenge â€“ Classify Your Own Text"],"metadata":{"id":"yFxPFagsE9mS"}},{"cell_type":"markdown","source":["### **Task 5**:  User Input Prediction\n","\n","*Instruction*: Write a function that allows the user to enter a text and receive a prediction from the trained model.\n"],"metadata":{"id":"IZwIOzHXFD1a"}},{"cell_type":"code","source":["def predict_sentiment(text):\n","    cleaned = preprocess(text)\n","    vectorized = tfidf.transform([cleaned])\n","    prediction = model.predict(vectorized)\n","    return \"Positive\" if prediction[0] == 1 else \"Negative\"\n","\n","# Try it out\n","predict_sentiment(\"The movie was so good and exciting!\")"],"metadata":{"id":"VpUFTR1JFDWk"},"execution_count":null,"outputs":[]}]}